#!/usr/bin/env python3
"""
ì‚¬ì´ì¢‹ì€ AI í¬ëŸ¼ - í”„ë¡œí•„ ë³´ë“œ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
Google Sheetsì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë¡œì»¬ ì •ì  ìì‚°ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•: python3 build.py
"""

import csv
import json
import os
import re
import urllib.request
import urllib.error
import time
import hashlib

# === ì„¤ì • ===
SHEET1_URL = "https://docs.google.com/spreadsheets/d/1O2Ya7XqKJpFaJScJp1fbPR6Y3Rgjn_qsVYgIy9E-k2M/gviz/tq?tqx=out:csv&gid=1551428892"
SHEET2_URL = "https://docs.google.com/spreadsheets/d/1u6TjlTKfBH5_9MnGCEG6C3NrjazX77tslbe3BxGN498/gviz/tq?tqx=out:csv&gid=225355410"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
IMAGES_DIR = os.path.join(BASE_DIR, "images")
DATA_DIR = os.path.join(BASE_DIR, "data")

# === CSV ë‹¤ìš´ë¡œë“œ ===
def download_csv(url):
    req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
    with urllib.request.urlopen(req) as resp:
        return resp.read().decode("utf-8")


def parse_csv(text):
    reader = csv.reader(text.strip().splitlines())
    headers = next(reader)
    rows = []
    for row in reader:
        if any(cell.strip() for cell in row):
            rows.append(row)
    return headers, rows


# === Google Drive ì´ë¯¸ì§€ ID ì¶”ì¶œ ===
def extract_drive_id(url):
    if not url or not url.strip():
        return None
    m = re.search(r"id=([a-zA-Z0-9_-]+)", url)
    if m:
        return m.group(1)
    m = re.search(r"/d/([a-zA-Z0-9_-]+)", url)
    if m:
        return m.group(1)
    return None


# === ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ===
def download_image(drive_id, filename):
    filepath = os.path.join(IMAGES_DIR, filename)
    if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
        return True  # ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨

    # Google Drive thumbnail URL (ê³ í™”ì§ˆ)
    url = f"https://drive.google.com/thumbnail?id={drive_id}&sz=w400"
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=15) as resp:
            data = resp.read()
            if len(data) < 500:  # ë„ˆë¬´ ì‘ìœ¼ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼
                print(f"  âš  {filename}: ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ìŒ ({len(data)} bytes), ìŠ¤í‚µ")
                return False
            with open(filepath, "wb") as f:
                f.write(data)
            return True
    except Exception as e:
        print(f"  âœ— {filename}: ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ - {e}")
        return False


# === ë©”ì¸ ë¹Œë“œ ===
def main():
    os.makedirs(IMAGES_DIR, exist_ok=True)
    os.makedirs(DATA_DIR, exist_ok=True)

    print("ğŸ“¥ ì‹œíŠ¸1 (ì‚¬ì „ë“±ë¡) ë‹¤ìš´ë¡œë“œ ì¤‘...")
    sheet1_text = download_csv(SHEET1_URL)
    h1, rows1 = parse_csv(sheet1_text)
    print(f"  â†’ {len(rows1)}í–‰ ë¡œë“œ")

    print("ğŸ“¥ ì‹œíŠ¸2 (ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜) ë‹¤ìš´ë¡œë“œ ì¤‘...")
    sheet2_text = download_csv(SHEET2_URL)
    h2, rows2 = parse_csv(sheet2_text)
    print(f"  â†’ {len(rows2)}í–‰ ë¡œë“œ")

    # --- ì‹œíŠ¸1 íŒŒì‹±: ì‚¬ì „ë“±ë¡ ë°ì´í„° (ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜, ë™ëª…ì´ì¸ ì§€ì›) ---
    # ì»¬ëŸ¼: íƒ€ì„ìŠ¤íƒ¬í”„, ì´ë©”ì¼, â‘  ì„±í•¨, â‘¡ ì†Œì†, â‘¢ ì§í•¨, â‘£ ìê¸°ì†Œê°œ, â‘¤ í”„ë¡œí•„ ì´ë¯¸ì§€, ..., [13] Column 14 (ì·¨ì†Œ/ì¤‘ë³µ í‘œì‹œ)
    all_entries = []
    for row in rows1:
        name = row[2].strip() if len(row) > 2 else ""
        if not name:
            continue
        # ì¤‘ë³µ í‘œì‹œëœ ì´ë¦„ ìŠ¤í‚µ
        if "(ì¤‘ë³µ)" in name:
            continue
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìŠ¤í‚µ
        if len(name) < 2 or not re.match(r"^[ê°€-í£a-zA-Z\s]+$", name.replace(" ", "")):
            print(f"  ìŠ¤í‚µ (ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¦„): '{name}'")
            continue

        col14 = row[13].strip() if len(row) > 13 else ""
        all_entries.append({
            "name": name,
            "organization": row[3].strip() if len(row) > 3 else "",
            "title": row[4].strip() if len(row) > 4 else "",
            "intro": row[5].strip() if len(row) > 5 else "",
            "image_url": row[6].strip() if len(row) > 6 else "",
            "col14": col14,
        })

    # ì¤‘ë³µ ì œì¶œ ì²˜ë¦¬: ê°™ì€ ì´ë¦„+ì†Œì†ì´ë©´ ë‚´ìš©ì´ ë” ì¶©ì‹¤í•œ ê²ƒì„ ìœ ì§€
    seen = {}
    for entry in all_entries:
        key = (entry["name"], entry["organization"])
        if key in seen:
            prev = seen[key]
            # ìê¸°ì†Œê°œê°€ ë” ì¶©ì‹¤í•œ ìª½ì„ ìœ ì§€ (ë¹ˆ ê°’ì´ë‚˜ ~~ ê°™ì€ ê±´ ë²„ë¦¼)
            prev_score = len(prev["intro"]) if prev["intro"] not in ("", "~~", "-") else 0
            curr_score = len(entry["intro"]) if entry["intro"] not in ("", "~~", "-") else 0
            if curr_score > prev_score:
                print(f"  ì¤‘ë³µ ì œì¶œ: {entry['name']} ({entry['organization']}) â†’ ìµœì‹  ìœ ì§€")
                seen[key] = entry
            else:
                print(f"  ì¤‘ë³µ ì œì¶œ: {entry['name']} ({entry['organization']}) â†’ ê¸°ì¡´ ìœ ì§€")
        else:
            seen[key] = entry

    # ì·¨ì†Œì ì œì™¸
    registration_list = []
    cancelled_count = 0
    for entry in seen.values():
        if "ì·¨ì†Œ" in entry["col14"]:
            print(f"  ì œì™¸ (ì°¸ì„ ì·¨ì†Œ): {entry['name']}")
            cancelled_count += 1
            continue
        registration_list.append(entry)

    print(f"\nâœ… ì‹œíŠ¸1 ìœ íš¨ ë“±ë¡ì: {len(registration_list)}ëª…")
    print(f"âŒ ì·¨ì†Œ/ì¤‘ë³µ ì œì™¸: {cancelled_count}ëª…")

    # --- ì‹œíŠ¸2 íŒŒì‹±: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì´ë¦„+ì†Œì†ìœ¼ë¡œ ë§¤ì¹­) ---
    # ì»¬ëŸ¼: (ë¹ˆ), ì—°ë²ˆ, ëŒ€êµ¬ë¶„, ì¤‘êµ¬ë¶„, ëª…ì°°êµ¬ë¶„, ìœ ì…êµ¬ë¶„, ì„±í•¨, ì‚¬ì „ë“±ë¡, ì—°ë½ì²˜, ì´ë©”ì¼, ì†Œì†, ì§í•¨, ...
    category_by_name = {}       # name â†’ category (ë‹¨ì¼ ë§¤ì¹­ìš©)
    category_by_name_org = {}   # (name, org) â†’ category (ë™ëª…ì´ì¸ìš©)
    for row in rows2:
        name = row[6].strip() if len(row) > 6 else ""
        if not name:
            continue
        mid_cat = row[3].strip() if len(row) > 3 else ""
        org = row[10].strip() if len(row) > 10 else ""

        # ì¹´ì¹´ì˜¤ â†’ AIãƒ»ê¸°ìˆ ë¡œ í†µí•©
        if mid_cat == "ì¹´ì¹´ì˜¤":
            mid_cat = "AIãƒ»ê¸°ìˆ "
        if mid_cat:
            category_by_name[name] = mid_cat
            category_by_name_org[(name, org)] = mid_cat

    print(f"âœ… ì‹œíŠ¸2 ë¶„ë¥˜ì: {len(category_by_name)}ëª…")

    # --- ì‹œíŠ¸1 ê¸°ë°˜ í”„ë¡œí•„ ìƒì„± (ë™ëª…ì´ì¸ í¬í•¨, ì „ì› í¬í•¨) ---
    profiles = []
    no_category = []

    for reg in registration_list:
        name = reg["name"]
        org = reg["organization"]
        # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­: ì´ë¦„+ì†Œì† â†’ ì´ë¦„ë§Œ â†’ ë¯¸ë¶„ë¥˜
        category = category_by_name_org.get((name, org), "")
        if not category:
            category = category_by_name.get(name, "")

        profile = {
            "name": name,
            "organization": org,
            "title": reg["title"],
            "intro": reg["intro"],
            "image_url": reg["image_url"],
            "category": category,
        }

        if not category:
            no_category.append(name)

        profiles.append(profile)

    # ì´ë¦„ìˆœ ì •ë ¬
    profiles.sort(key=lambda p: p["name"])

    print(f"\nğŸ“Š ê²°ê³¼: ì´ {len(profiles)}ëª…")
    if no_category:
        print(f"  âš  ì¹´í…Œê³ ë¦¬ ë¯¸ë¶„ë¥˜: {len(no_category)}ëª… â†’ 'ê¸°íƒ€'ë¡œ ë¶„ë¥˜")
        for n in no_category:
            print(f"    - {n}")
        for p in profiles:
            if not p["category"]:
                p["category"] = "ê¸°íƒ€"

    # --- ì¹´í…Œê³ ë¦¬ í†µê³„ ---
    cat_counts = {}
    for p in profiles:
        c = p["category"]
        cat_counts[c] = cat_counts.get(c, 0) + 1

    print("\nğŸ“‹ ì¹´í…Œê³ ë¦¬ ë¶„í¬:")
    for cat, count in sorted(cat_counts.items(), key=lambda x: -x[1]):
        print(f"  {cat}: {count}ëª…")

    # --- ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ ì´ë¯¸ì§€ í´ë” ì´ˆê¸°í™”) ---
    import glob as glob_mod
    old_images = glob_mod.glob(os.path.join(IMAGES_DIR, "*.jpg"))
    if old_images:
        print(f"\nğŸ—‘ï¸  ê¸°ì¡´ ì´ë¯¸ì§€ {len(old_images)}ê°œ ì‚­ì œ...")
        for f in old_images:
            os.remove(f)

    print(f"\nğŸ–¼ï¸  í”„ë¡œí•„ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    success = 0
    fail = 0
    for i, p in enumerate(profiles):
        drive_id = extract_drive_id(p["image_url"])
        if drive_id:
            # íŒŒì¼ëª…: Google Drive ID ê¸°ë°˜ (ì‚¬ëŒ-ì´ë¯¸ì§€ ë§¤í•‘ ì•ˆì •ì )
            filename = f"{drive_id}.jpg"
            ok = download_image(drive_id, filename)
            if ok:
                p["image"] = f"images/{filename}"
                success += 1
            else:
                p["image"] = None
                fail += 1
            time.sleep(0.3)  # Rate limit ë°©ì§€
        else:
            p["image"] = None

    print(f"  âœ… ì„±ê³µ: {success}  âœ— ì‹¤íŒ¨: {fail}")

    # --- JSON ì¶œë ¥ ---
    output = []
    for i, p in enumerate(profiles):
        output.append({
            "id": i + 1,
            "name": p["name"],
            "organization": p["organization"],
            "title": p["title"],
            "intro": p["intro"],
            "category": p["category"],
            "image": p["image"],
        })

    # ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì •ì˜ (í•„í„° ë²„íŠ¼ ìˆœì„œ)
    category_order = [
        "êµì›",
        "ì¥í•™ì‚¬",
        "ì •ì±…ãƒ»ì—°êµ¬",
        "êµìœ¡í˜ì‹ ãƒ»ì—ë“€í…Œí¬",
        "AIãƒ»ê¸°ìˆ ",
        "ì‚¬ë””ì„¸ ê°•ì‚¬",
    ]

    output_data = {
        "categories": category_order,
        "profiles": output,
        "total": len(output),
        "built_at": time.strftime("%Y-%m-%d %H:%M:%S"),
    }

    json_path = os.path.join(DATA_DIR, "profiles.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    # JS íŒŒì¼ë„ í•¨ê»˜ ìƒì„± (file:// í”„ë¡œí† ì½œ í˜¸í™˜)
    js_path = os.path.join(DATA_DIR, "profiles.js")
    with open(js_path, "w", encoding="utf-8") as f:
        f.write("const PROFILE_DATA = ")
        json.dump(output_data, f, ensure_ascii=False, indent=2)
        f.write(";")

    print(f"\nğŸ‰ ë¹Œë“œ ì™„ë£Œ!")
    print(f"  ğŸ“„ {json_path}")
    print(f"  ğŸ“„ {js_path}")
    print(f"  ğŸ–¼ï¸  {IMAGES_DIR}/ ({success}ê°œ ì´ë¯¸ì§€)")
    print(f"  ğŸ‘¥ ì´ {len(output)}ëª… í”„ë¡œí•„")


if __name__ == "__main__":
    main()
